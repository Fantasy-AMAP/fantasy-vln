Path:
  scene: "lhvln/data/hm3d/"
  scene_dataset: "lhvln/data/hm3d/hm3d_annotated_basis.scene_dataset_config.json"

  episode_data: "lhvln/data/episode_task"
  task_data: "lhvln/data/task"
  step_task_data: "lhvln/data/step_task"
  train_batch: ['/batch_1', '/batch_2', '/batch_3', '/batch_4', '/batch_5']
  val_batch: ['/batch_6']
  test_batch: ['/batch_7', '/batch_8']
  split_by_scene: True

  save_checkpoints: "./save_checkpoints"

  tensorboard_path: "./run"
  # output_dir: "./output"

Train:
  mode: 'test'
  tensorboard: False
  best_checkpoint: null
  load_checkpoint: False
  save_ckpt_per_epochs: 10

  batch_size: 1
  num_epochs: 20
  ignoreid: -100
  max_step: 500
  gradient_accumulation_step: 2
  num_warmup_steps: 1000

  success_dis: 1

Model:
  model_name: "VLM Model"
  resume_from_checkpoint: null  # if you have a checkpoint and you want to load model from that state, here is the path you need to add
  from_scratch: True  # if your model is not vicuna 7b or llama 8b, set it to True
  feat_dropout: 0.4
  temperature: 1.0
  image_feat_size: 1024
  angle_feat_size: 4
  enc_full_graph: True
  num_pano_layers: 2
  max_memory: 20  # based on your vram
